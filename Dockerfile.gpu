# syntax=docker/dockerfile:1.6

# GPU-ready image. Relies on NVIDIA driver on host and nvidia-container-toolkit.
# Uses PyTorch CUDA wheels (cu121) that bundle CUDA runtime inside the wheel.

FROM python:3.12-slim AS base

ENV PYTHONDONTWRITEBYTECODE=1 \
    PYTHONUNBUFFERED=1

RUN apt-get update && \
    apt-get install -y --no-install-recommends \
      build-essential \
      curl \
      ca-certificates \
      poppler-utils \
      tesseract-ocr \
      tesseract-ocr-eng \
      tesseract-ocr-rus \
      libgl1 \
      libglib2.0-0 \
      libsm6 libxrender1 libxext6 \
      ghostscript \
      fonts-dejavu \
      antiword \
      unrtf && \
    rm -rf /var/lib/apt/lists/*

WORKDIR /app

COPY pyproject.toml README.md ./
COPY src ./src

# Install PyTorch CUDA wheels first (cu121), then project with GPU extras
RUN pip install --no-cache-dir --upgrade pip && \
    pip install --no-cache-dir --index-url https://download.pytorch.org/whl/cu121 \
        torch torchvision torchaudio && \
    pip install --no-cache-dir .[gpu]

EXPOSE 8080

ENV NC_APP_HOST=0.0.0.0 NC_APP_PORT=8080 \
    # Prefer CUDA when available inside GPU profile
    NC_CAPTION_DEVICE=cuda \
    NC_OCR_GPU=true

CMD ["uvicorn", "nc_parser.api.main:app", "--host", "0.0.0.0", "--port", "8080"]


